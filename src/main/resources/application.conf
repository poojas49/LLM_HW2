# Spark settings
spark {
  appName = "LLM-Training"
  masterUrl = "local[*]" # default value, can be overridden
  executorMemory = "4g"
  executorCores = 2
  driverMemory = "4g"
  defaultParallelism = 8
  sqlShufflePartitions = 8
  localDir = "temp"
  hadoop {
    fsDefaultFS = "file:///"
    fileOutputCommitterAlgorithmVersion = 2
  }
}

# Job-specific settings
job {
  sliding {
    inputPath = "data/input/sliding"
    outputPath = "data/output/sliding"
  }
  training {
    inputPath = "data/output/sliding"
    outputPath = "data/output/model"
  }
}

job {
  sliding {
    embeddingFile = "file:///Users/poojashinde/IntelliJProjects/LLM-Training/data/input/embedding"
    tokenizationFile = "file:///Users/poojashinde/IntelliJProjects/LLM-Training/data/input/tokenization"
    outputDir = "file:///Users/poojashinde/IntelliJProjects/LLM-Training/data/output/sliding"
    windowSize = 4
    embeddingDim = 4
    batchSize = 1000
  }
}

training {
  inputPath = "data/output/sliding"
  outputPath = "data/output/model"
  numEpochs = 10
  learningRate = 0.001
  seed = 12345
  inputSize = 50
  hiddenLayerSize = 128
  scoreIterationListenerFrequency = 10
}
